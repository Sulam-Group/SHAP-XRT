{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from dataset import BooleanDataset\n",
    "from model import BooleanF\n",
    "from shaplit import shaplit\n",
    "\n",
    "figure_dir = os.path.join(root_dir, \"figures\", \"boolean\")\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\", font_scale=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `m` is the number of samples\n",
    "# `k` is the number of components in each sample\n",
    "# `n` is the number of features in each component\n",
    "m = int(1e03)\n",
    "k = 2\n",
    "n = 5\n",
    "# `t` is the threshold\n",
    "t = 3\n",
    "# `N` is the set of features `N = {0, 1, ..., (k*n)-1}`\n",
    "N = set(range(k * n))\n",
    "\n",
    "# initialize the dataset\n",
    "dataset = BooleanDataset(m, k, n)\n",
    "# initialize the ground-truth Boolean function\n",
    "model = BooleanF(n, t)\n",
    "\n",
    "# find positive samples\n",
    "X = dataset.data\n",
    "Y = model(X)\n",
    "\n",
    "P_idx = Y.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `K` is the number of null statistics to compute\n",
    "# `M` is the number of reference samples to draw\n",
    "K = int(100000)\n",
    "M = 1\n",
    "\n",
    "# `x` is the first positive sample in the dataset\n",
    "idx = 0\n",
    "x = X[P_idx[idx]]\n",
    "y = Y[P_idx[idx]]\n",
    "\n",
    "# for a feature `j` and a set of features `C \\in [n] \\setminus \\{j\\}`,\n",
    "# `P` contains the p-value of the SHAPLIT procedure\n",
    "# `B` contains the upper bound `1 - \\gamma_{j,C}`\n",
    "P = np.empty((2 ** ((k * n) - 1),))\n",
    "B = np.empty_like(P)\n",
    "# for each feature in `x`\n",
    "for j, xj in enumerate(x[0]):\n",
    "    # only consider important features,\n",
    "    # i.e. features above the threshold\n",
    "    if np.abs(xj) < t:\n",
    "        continue\n",
    "\n",
    "    # `S` is the set of features in `x` that are not `j`\n",
    "    # `q` is a counter for the number of tests performed\n",
    "    S = N - {j}\n",
    "    q = 0\n",
    "\n",
    "    # for each subset `C` of `S`\n",
    "    for c in range(len(S) + 1):\n",
    "        CC = combinations(S, c)\n",
    "        for C in CC:\n",
    "            C = set(C)\n",
    "\n",
    "            # estimate the summand `\\gamma_{j,C}` in the\n",
    "            # Shapley value of feature `j`\n",
    "            C.add(j)\n",
    "            f = model(dataset.cond(x, C, K))\n",
    "\n",
    "            C.remove(j)\n",
    "            f_null = model(dataset.cond(x, C, K))\n",
    "\n",
    "            g = (f - f_null).mean().item()\n",
    "\n",
    "            # compute the p-value of the SHAPLIT procedure\n",
    "            p = shaplit(model, dataset.cond, x, j, C, K=K, M=M).item()\n",
    "\n",
    "            B[q] = 1 - g\n",
    "            P[q] = p\n",
    "            q += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to reproduce Fig. 1.a\n",
    "_, ax = plt.subplots(figsize=(16 / 2, 9 / 2))\n",
    "ax.scatter(B, P, marker=\"x\", alpha=0.5)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"bound\")\n",
    "ax.set_xlabel(r\"$1 - \\hat{\\gamma}_{j,C}$\")\n",
    "ax.set_ylabel(r\"$\\hat{p}^{SHAPLIT}_{j,C}$\")\n",
    "ax.set_xlim(-0.001, 0.05)\n",
    "ax.set_ylim(-0.001, 0.05)\n",
    "ax.set_xticks([0, 0.05 / 3, 2 * 0.05 / 3, 0.05])\n",
    "ax.set_yticks([0, 0.05 / 3, 2 * 0.05 / 3, 0.05])\n",
    "ax.set_xticklabels([0, None, None, 0.05])\n",
    "ax.set_yticklabels([0, None, None, 0.05])\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.savefig(os.path.join(figure_dir, \"bound.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `K` is the number of null statistics to compute\n",
    "# `l` is the number of positive features to aggregate over\n",
    "K = 1000\n",
    "l = 20\n",
    "\n",
    "# for a feature `j` and a set of features `C \\in [n] \\setminus \\{j\\}`,\n",
    "# `P` contains the p-value of the SHAPLIT procedure\n",
    "# `B` contains the upper bound `1 - \\gamma_{j,C}`\n",
    "# `CDF_P` contain the cumulative distribution function of the p-values\n",
    "# `CDF_B` contain the cumulative distribution function of the upper bounds\n",
    "P = np.empty((l, 2 ** ((k * n) - 1)))\n",
    "B = np.empty_like(P)\n",
    "CDF_P = np.empty_like(P)\n",
    "CDF_B = np.empty_like(P)\n",
    "\n",
    "# `i` is a counter for the number of important features\n",
    "i = 0\n",
    "pbar = tqdm(total=l)\n",
    "# repeat until `l` important features have been aggregated\n",
    "while i < l:\n",
    "    x = X[P_idx[i]]\n",
    "    # for each feature in `x`\n",
    "    for j, xj in enumerate(x[0]):\n",
    "        # only consider important features,\n",
    "        # i.e. features above the threshold\n",
    "        if xj < t:\n",
    "            continue\n",
    "\n",
    "        # `S` is the set of features in `x` that are not `j`\n",
    "        # `q` is a counter for the number of tests performed\n",
    "        S = N - {j}\n",
    "        q = 0\n",
    "\n",
    "        # for each subset `C` of `S`\n",
    "        for c in range(len(S) + 1):\n",
    "            CC = combinations(S, c)\n",
    "            for C in CC:\n",
    "                C = set(C)\n",
    "                C.add(j)\n",
    "\n",
    "                # estimate the summand `\\gamma_{j,C}` in the\n",
    "                f = model(dataset.cond(x, C, K))\n",
    "\n",
    "                C.remove(j)\n",
    "                f_null = model(dataset.cond(x, C, K))\n",
    "\n",
    "                g = (f - f_null).mean().item()\n",
    "\n",
    "                # compute the p-value of the SHAPLIT procedure\n",
    "                p = shaplit(model, dataset.cond, x, j, C, K=K, M=M).item()\n",
    "\n",
    "                B[i, q] = 1 - g\n",
    "                P[i, q] = p\n",
    "                q += 1\n",
    "\n",
    "        # compute the cumulative distribution function of the p-values\n",
    "        sort_p_idx = np.argsort(P[i])\n",
    "        P[i] = P[i][sort_p_idx]\n",
    "        CDF_P[i] = 1.0 * np.arange(len(P[i])) / len(P[i] - 1)\n",
    "\n",
    "        # compute the cumulative distribution function of the upper bounds\n",
    "        sort_b_idx = np.argsort(B[i])\n",
    "        B[i] = B[i][sort_b_idx]\n",
    "        CDF_B[i] = 1.0 * np.arange(len(B[i])) / len(B[i] - 1)\n",
    "\n",
    "        i += 1\n",
    "        pbar.update(1)\n",
    "        if i == l:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to reproduce Fig. 1.b\n",
    "_, ax = plt.subplots(figsize=(16 / 2, 9 / 2))\n",
    "\n",
    "uu = 10 ** np.linspace(-3, 0, 50)\n",
    "interp_CDF_P = np.empty((l, 50))\n",
    "interp_CDF_B = np.empty_like(interp_CDF_P)\n",
    "for i in range(l):\n",
    "    interp_CDF_P[i] = np.interp(uu, P[i], CDF_P[i])\n",
    "    interp_CDF_B[i] = np.interp(uu, B[i], CDF_B[i])\n",
    "\n",
    "ax.plot(uu, interp_CDF_P.mean(axis=0), \"b-\", label=r\"$\\hat{p}^{SHAPLIT}_{j,C}$\")\n",
    "ax.fill_between(\n",
    "    uu,\n",
    "    np.percentile(interp_CDF_P, 5, axis=0),\n",
    "    np.percentile(interp_CDF_P, 95, axis=0),\n",
    "    alpha=0.3,\n",
    "    color=\"b\",\n",
    ")\n",
    "ax.plot(uu, interp_CDF_B.mean(axis=0), \"r-\", label=r\"$1 - \\hat{\\gamma}_{j,C}$\")\n",
    "ax.fill_between(\n",
    "    uu,\n",
    "    np.percentile(interp_CDF_B, 5, axis=0),\n",
    "    np.percentile(interp_CDF_B, 95, axis=0),\n",
    "    alpha=0.3,\n",
    "    color=\"r\",\n",
    ")\n",
    "ax.set_ylabel(\"Cumulative distribution\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(None, 0.8)\n",
    "ax.set_ylim(None, 0.8)\n",
    "ax.axvline(0.05, c=\"k\", linestyle=\"--\", label=\"0.05\")\n",
    "ax.legend()\n",
    "plt.savefig(os.path.join(figure_dir, \"cdf.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4af04b5eb304d7211481e03d838d620ccabc520a197427e4bca5f74ba487b2a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
