{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root_dir = \"../../../\"\n",
    "experiment_dir = os.path.join(root_dir, \"experiments\", \"BBBC041\")\n",
    "data_dir = os.path.join(experiment_dir, \"data\")\n",
    "trophozoite_dir = os.path.join(data_dir, \"trophozoite\")\n",
    "explanation_dir = os.path.join(experiment_dir, \"explanations\")\n",
    "explainer_dir = os.path.join(explanation_dir, \"hexp\", \"800\", \"absolute_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\", pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(experiment_dir, \"pretrained_model\", \"model.pt\"),\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "unnorm = transforms.Normalize(-mean / std, 1 / std)\n",
    "dataset = ImageFolder(os.path.join(trophozoite_dir, \"val\"), transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, num_workers=4, shuffle=False)\n",
    "image_names = [os.path.basename(x[0]).split(\".\")[0] for x in dataset.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrant_df = pd.read_pickle(os.path.join(data_dir, \"quadrant_labels\"))\n",
    "flipped_images = np.load(os.path.join(data_dir, \"flipped_images.npy\"))\n",
    "\n",
    "logit_threshold = 0.5\n",
    "w = torch.tensor([1 / 4, 1 / 12, 1 / 12, 1 / 12, 1 / 12, 1 / 12, 1 / 12, 1 / 4])\n",
    "\n",
    "PP = 0\n",
    "TP = 0\n",
    "perfect_retrieval = 0\n",
    "quadrant_target = []\n",
    "quadrant_importance = []\n",
    "quadrant_importance_cauchy = []\n",
    "df = []\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    input, label = data\n",
    "\n",
    "    image_name = image_names[i]\n",
    "    quadrant_labels = quadrant_df.at[image_name, \"quadrant_labels\"]\n",
    "\n",
    "    if len(flipped_images) > 0 and image_name in flipped_images:\n",
    "        continue\n",
    "\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    prediction = output.argmax(dim=1)\n",
    "\n",
    "    PP += prediction\n",
    "    TP += label\n",
    "\n",
    "    if prediction == 1:\n",
    "        with open(\n",
    "            os.path.join(explainer_dir, f\"{image_name}_{logit_threshold}.pkl\"), \"rb\"\n",
    "        ) as f:\n",
    "            explanation = pickle.load(f)\n",
    "\n",
    "        _, _, shaplit_map, p = explanation\n",
    "        P = torch.ones((4, 8))\n",
    "        P_cauchy = torch.ones((4, 8))\n",
    "        for j, jp in p:\n",
    "            for k, (C, pp) in enumerate(jp):\n",
    "                P[j, k] = pp\n",
    "                eps = 1e-04\n",
    "                P_cauchy[j, k] = np.tan((1 / 2 - np.clip(pp, eps, 1 - eps)) * np.pi)\n",
    "\n",
    "        P = torch.matmul(P, 2 * w)\n",
    "        threshold = torch.quantile(P, 0.7)\n",
    "        if len(P.unique()) == 1:\n",
    "            importance = 4 * [1]\n",
    "        else:\n",
    "            importance = (P < threshold_cauchy).long().tolist()\n",
    "\n",
    "        P_cauchy = 1 / 2 - torch.arctan(torch.matmul(P_cauchy, w)) / torch.pi\n",
    "        threshold_cauchy = torch.quantile(P_cauchy, 0.7)\n",
    "        if len(P_cauchy.unique()) == 1:\n",
    "            importance_cauchy = 4 * [1]\n",
    "        else:\n",
    "            importance_cauchy = (P_cauchy < 0.05).long().tolist()\n",
    "        print(\n",
    "            quadrant_labels,\n",
    "            P,\n",
    "            P_cauchy,\n",
    "            threshold,\n",
    "            threshold_cauchy,\n",
    "            importance,\n",
    "            importance_cauchy,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        importance = 4 * [0]\n",
    "        importance_cauchy = 4 * [0]\n",
    "    df.append(\n",
    "        {\n",
    "            \"image_name\": image_name,\n",
    "            \"importance\": importance,\n",
    "            \"importance_cauchy\": importance_cauchy,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    quadrant_target.extend(quadrant_labels)\n",
    "    quadrant_importance.extend(importance)\n",
    "    quadrant_importance_cauchy.extend(importance_cauchy)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.to_pickle(os.path.join(explainer_dir, \"quadrant_importance.pkl\"))\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    quadrant_target,\n",
    "    quadrant_importance,\n",
    "    pos_label=1,\n",
    "    average=\"binary\",\n",
    ")\n",
    "precision_cauchy, recall_cauchy, f1_cauchy, _ = precision_recall_fscore_support(\n",
    "    quadrant_target,\n",
    "    quadrant_importance_cauchy,\n",
    "    pos_label=1,\n",
    "    average=\"binary\",\n",
    ")\n",
    "print(\n",
    "    f\"TP: {TP}\",\n",
    "    f\"PP: {PP}\",\n",
    "    f\"precision: {precision:.2f}\",\n",
    "    f\"recall: {recall:.2f}\",\n",
    "    f\"f1: {f1:.2f}\",\n",
    "    f\"precision_cauchy: {precision_cauchy:.2f}\",\n",
    "    f\"recall_cauchy: {recall_cauchy:.2f}\",\n",
    "    f\"f1_cauchy: {f1_cauchy:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda102')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd8c972ecb72e669b05b9af0bbaad01a2103da39053b5ad2ceb924e75319f022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
